{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Reading-In-Data\" data-toc-modified-id=\"Reading-In-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reading In Data</a></span></li><li><span><a href=\"#Analyzing-Data\" data-toc-modified-id=\"Analyzing-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyzing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#High-Level-.describe()\" data-toc-modified-id=\"High-Level-.describe()-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>High Level .describe()</a></span></li><li><span><a href=\"#Top-N-by-CV-ROC\" data-toc-modified-id=\"Top-N-by-CV-ROC-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Top-N by CV-ROC</a></span></li><li><span><a href=\"#Finding-Maximum-CV-ROC-by-weight-scheme\" data-toc-modified-id=\"Finding-Maximum-CV-ROC-by-weight-scheme-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Finding Maximum CV-ROC by weight scheme</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this notebook we need to analyze the received experimental data and arrive to some inetertsing results and explanations that we'll add to the paper \n",
    "\n",
    "The metrics to consider for any analysis: \n",
    "\n",
    " * \"best\" by ROC on CV and/or test (sometimes ROC si ste to 0 or -1 as an error, you should ignore those results)\n",
    " * another way to consider is \"best\" by F1: we have F1_fake and F1-real separately (more interetsed in fake actually but better to analyzie for both - see how Veronica and Rada did it in their paper).\n",
    "\n",
    "\n",
    "What we might want to learn: \n",
    "\n",
    "* which experiment is the best overall?  \n",
    "\n",
    "* which weight scheme gave the best results more frequently?  That is, may be the best weighting scheme. \n",
    "    \n",
    "* which classifier performed better?  \n",
    "\n",
    "* which feature combinations are better to use? \n",
    "\n",
    "* what are the feature vector sizes for what combinations? Any characteristics for those. Which potentially overfit and cannot be used on our dataset?   (might be useful in the future for larger datasets) \n",
    "\n",
    "* ... so on\n",
    "\n",
    "As the result of ths investigatin you should be able to  provide teh following recommenation to the reader (very rough sample): \n",
    "\n",
    "we prepared this dataset for the Urdu language. Urdu doesn't have such tools as other languages taht's why we didn't use the facy features as in (Veronica and Rada, 2018) yet we tried to provide a baseline classifier and recommend the best set of readily available feature, i.e., N-grams of different types, as well as analyzed various hyperparameters such as weighting schemes for those features. We've tried our experiments using a number of popular and available classifiers and  found out that: \n",
    "\n",
    "* the best result was with such  n-gram combination - weighting scheme - classifier  (actually, by 2 or 3 metrics, we might get a few \"bests\")\n",
    "* the overall consistently strongly performing weighting scheme is .... \n",
    "    * (also, logent and rela give aweful times but it might be because they are manually written by us - we'll see whether to add this) \n",
    " \n",
    "* the recommended classifier is.. \n",
    "\n",
    "* the promising n-gram combinations are ... (we need to exclude the combinatios with overly large feature #)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE THIS: needed to make it run on Alisa's laptop \n",
    "import sys \n",
    "#sys.executable, sys.path\n",
    "sys.path.append('/Users/alisa/workspace/Urdu_Fake_News/envname/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('results/results.csv')\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram-feat-comb</th>\n",
       "      <th>char N-gram</th>\n",
       "      <th>word N-gram</th>\n",
       "      <th>func N-gram</th>\n",
       "      <th>total_feat_num</th>\n",
       "      <th>weight scheme</th>\n",
       "      <th>classifier</th>\n",
       "      <th>cv-acc</th>\n",
       "      <th>cv-balanced_acc</th>\n",
       "      <th>cv-roc</th>\n",
       "      <th>cv-f1-fake</th>\n",
       "      <th>acc</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>roc</th>\n",
       "      <th>f1_fake</th>\n",
       "      <th>f1_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-0-0 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>binary</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-0-0 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>binary</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-0-0 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>binary</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-0-0 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>binary</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-0-0 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>binary</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       N-gram-feat-comb  char N-gram  word N-gram  func N-gram  \\\n",
       "0  1-0-0 char-word-func            1            0            0   \n",
       "1  1-0-0 char-word-func            1            0            0   \n",
       "2  1-0-0 char-word-func            1            0            0   \n",
       "3  1-0-0 char-word-func            1            0            0   \n",
       "4  1-0-0 char-word-func            1            0            0   \n",
       "\n",
       "   total_feat_num weight scheme              classifier  cv-acc  \\\n",
       "0             101        binary      LogisticRegression    0.66   \n",
       "1             101        binary               LinearSVC    0.73   \n",
       "2             101        binary                     SVC    0.67   \n",
       "3             101        binary  DecisionTreeClassifier    0.72   \n",
       "4             101        binary  RandomForestClassifier    0.65   \n",
       "\n",
       "   cv-balanced_acc  cv-roc  cv-f1-fake   acc  balanced_acc   roc  f1_fake  \\\n",
       "0             0.64    0.79        0.52  0.75          0.72  0.85     0.65   \n",
       "1             0.73    0.81        0.72  0.80          0.79  0.00     0.76   \n",
       "2             0.64    0.79        0.46  0.77          0.75  0.00     0.68   \n",
       "3             0.72    0.72        0.68  0.77          0.76  0.78     0.72   \n",
       "4             0.61    0.80        0.32  0.72          0.68  0.89     0.52   \n",
       "\n",
       "   f1_real  \n",
       "0     0.80  \n",
       "1     0.83  \n",
       "2     0.82  \n",
       "3     0.80  \n",
       "4     0.80  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char N-gram</th>\n",
       "      <th>word N-gram</th>\n",
       "      <th>func N-gram</th>\n",
       "      <th>total_feat_num</th>\n",
       "      <th>cv-acc</th>\n",
       "      <th>cv-balanced_acc</th>\n",
       "      <th>cv-roc</th>\n",
       "      <th>cv-f1-fake</th>\n",
       "      <th>acc</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>roc</th>\n",
       "      <th>f1_fake</th>\n",
       "      <th>f1_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.00000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>2880.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>9049.80000</td>\n",
       "      <td>0.484639</td>\n",
       "      <td>0.468149</td>\n",
       "      <td>0.554896</td>\n",
       "      <td>0.291660</td>\n",
       "      <td>0.661969</td>\n",
       "      <td>0.629722</td>\n",
       "      <td>0.563872</td>\n",
       "      <td>0.425931</td>\n",
       "      <td>0.741056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.925605</td>\n",
       "      <td>1.925605</td>\n",
       "      <td>1.925605</td>\n",
       "      <td>11885.41162</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>0.433719</td>\n",
       "      <td>0.460627</td>\n",
       "      <td>0.460304</td>\n",
       "      <td>0.088442</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>0.339367</td>\n",
       "      <td>0.296325</td>\n",
       "      <td>0.071564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>922.75000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4079.50000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9027.00000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>41125.00000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       char N-gram  word N-gram  func N-gram  total_feat_num       cv-acc  \\\n",
       "count  2880.000000  2880.000000  2880.000000      2880.00000  2880.000000   \n",
       "mean      1.600000     1.600000     1.600000      9049.80000     0.484639   \n",
       "std       1.925605     1.925605     1.925605     11885.41162     0.436200   \n",
       "min       0.000000     0.000000     0.000000        18.00000    -1.000000   \n",
       "25%       0.000000     0.000000     0.000000       922.75000     0.550000   \n",
       "50%       1.000000     1.000000     1.000000      4079.50000     0.580000   \n",
       "75%       3.000000     3.000000     3.000000      9027.00000     0.650000   \n",
       "max       6.000000     6.000000     6.000000     41125.00000     0.830000   \n",
       "\n",
       "       cv-balanced_acc       cv-roc   cv-f1-fake          acc  balanced_acc  \\\n",
       "count      2880.000000  2880.000000  2880.000000  2880.000000   2880.000000   \n",
       "mean          0.468149     0.554896     0.291660     0.661969      0.629722   \n",
       "std           0.433719     0.460627     0.460304     0.088442      0.108911   \n",
       "min          -1.000000    -1.000000    -1.000000     0.480000      0.490000   \n",
       "25%           0.500000     0.590000     0.010000     0.580000      0.510000   \n",
       "50%           0.570000     0.670000     0.490000     0.640000      0.630000   \n",
       "75%           0.640000     0.750000     0.620000     0.730000      0.720000   \n",
       "max           0.830000     0.910000     0.820000     0.870000      0.870000   \n",
       "\n",
       "               roc      f1_fake      f1_real  \n",
       "count  2880.000000  2880.000000  2880.000000  \n",
       "mean      0.563872     0.425931     0.741056  \n",
       "std       0.339367     0.296325     0.071564  \n",
       "min       0.000000     0.000000     0.170000  \n",
       "25%       0.382500     0.070000     0.720000  \n",
       "50%       0.710000     0.540000     0.730000  \n",
       "75%       0.810000     0.680000     0.790000  \n",
       "max       0.960000     0.850000     0.900000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results and anayze each column.   What can we tell from this very high level analysis? \n",
    "Note that values -1 and 0 for ROC are when error occured or this metric could not eb applied (not all classifiers support it, do you know why?) \n",
    "\n",
    "For other metrics if the value is 0, so it is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-N by CV-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram-feat-comb</th>\n",
       "      <th>char N-gram</th>\n",
       "      <th>word N-gram</th>\n",
       "      <th>func N-gram</th>\n",
       "      <th>total_feat_num</th>\n",
       "      <th>weight scheme</th>\n",
       "      <th>classifier</th>\n",
       "      <th>cv-acc</th>\n",
       "      <th>cv-balanced_acc</th>\n",
       "      <th>cv-roc</th>\n",
       "      <th>cv-f1-fake</th>\n",
       "      <th>acc</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>roc</th>\n",
       "      <th>f1_fake</th>\n",
       "      <th>f1_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2-0-1 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1848</td>\n",
       "      <td>binary</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2-0-1 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1848</td>\n",
       "      <td>binary</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-0-0 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1555</td>\n",
       "      <td>binary</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2-0-0 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1555</td>\n",
       "      <td>binary</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2-1-0 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5575</td>\n",
       "      <td>binary</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         N-gram-feat-comb  char N-gram  word N-gram  func N-gram  \\\n",
       "249  2-0-1 char-word-func            2            0            1   \n",
       "250  2-0-1 char-word-func            2            0            1   \n",
       "9    2-0-0 char-word-func            2            0            0   \n",
       "10   2-0-0 char-word-func            2            0            0   \n",
       "201  2-1-0 char-word-func            2            1            0   \n",
       "\n",
       "     total_feat_num weight scheme classifier  cv-acc  cv-balanced_acc  cv-roc  \\\n",
       "249            1848        binary  LinearSVC    0.82             0.82    0.91   \n",
       "250            1848        binary        SVC    0.83             0.83    0.91   \n",
       "9              1555        binary  LinearSVC    0.80             0.80    0.90   \n",
       "10             1555        binary        SVC    0.80             0.81    0.90   \n",
       "201            5575        binary  LinearSVC    0.80             0.80    0.90   \n",
       "\n",
       "     cv-f1-fake   acc  balanced_acc  roc  f1_fake  f1_real  \n",
       "249        0.81  0.84          0.84  0.0     0.81     0.87  \n",
       "250        0.82  0.84          0.83  0.0     0.80     0.87  \n",
       "9          0.79  0.84          0.83  0.0     0.80     0.87  \n",
       "10         0.80  0.85          0.84  0.0     0.81     0.88  \n",
       "201        0.78  0.87          0.86  0.0     0.84     0.89  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/get-n-largest-values-from-a-particular-column-in-pandas-dataframe/\n",
    "results.nlargest(5, ['cv-roc']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already kinda see that 2 - 0 - 1 , 2 - 0 -0 , or 2 - 1 -0 are teh best o teh Cross-Validation runs. Will this hold for tests? (actually, for test never mind, the function didn't apply there - then check the F-scores, whether they stay high  for  CV and Test runs. If they are sufficiently high (show up in top5, top 10), then we are on a good track).   \n",
    "\n",
    "\n",
    "Note that the 1st column is the # of the line in the result table and can be tretaed as the ID of an experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Maximum CV-ROC by weight scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram-feat-comb</th>\n",
       "      <th>char N-gram</th>\n",
       "      <th>word N-gram</th>\n",
       "      <th>func N-gram</th>\n",
       "      <th>total_feat_num</th>\n",
       "      <th>weight scheme</th>\n",
       "      <th>classifier</th>\n",
       "      <th>cv-acc</th>\n",
       "      <th>cv-balanced_acc</th>\n",
       "      <th>cv-roc</th>\n",
       "      <th>cv-f1-fake</th>\n",
       "      <th>acc</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>roc</th>\n",
       "      <th>f1_fake</th>\n",
       "      <th>f1_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2-0-1 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1848</td>\n",
       "      <td>binary</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2-0-1 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1848</td>\n",
       "      <td>logent</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2-2-2 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11448</td>\n",
       "      <td>none (tf)</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>2-2-2 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11448</td>\n",
       "      <td>norm</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1-0-1 char-word-func</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>relat</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2-0-0 char-word-func</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1555</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          N-gram-feat-comb  char N-gram  word N-gram  func N-gram  \\\n",
       "249   2-0-1 char-word-func            2            0            1   \n",
       "730   2-0-1 char-word-func            2            0            1   \n",
       "1599  2-2-2 char-word-func            2            2            2   \n",
       "1583  2-2-2 char-word-func            2            2            2   \n",
       "1943  1-0-1 char-word-func            1            0            1   \n",
       "996   2-0-0 char-word-func            2            0            0   \n",
       "\n",
       "      total_feat_num weight scheme              classifier  cv-acc  \\\n",
       "249             1848        binary               LinearSVC    0.82   \n",
       "730             1848        logent                     SVC    0.55   \n",
       "1599           11448     none (tf)      AdaBoostClassifier    0.81   \n",
       "1583           11448          norm      AdaBoostClassifier    0.81   \n",
       "1943             394         relat      AdaBoostClassifier    0.75   \n",
       "996             1555         tfidf  RandomForestClassifier    0.66   \n",
       "\n",
       "      cv-balanced_acc  cv-roc  cv-f1-fake   acc  balanced_acc   roc  f1_fake  \\\n",
       "249              0.82    0.91        0.81  0.84          0.84  0.00     0.81   \n",
       "730              0.50    0.90        0.00  0.57          0.50  0.00     0.00   \n",
       "1599             0.80    0.89        0.78  0.85          0.84  0.93     0.82   \n",
       "1583             0.80    0.89        0.78  0.85          0.84  0.93     0.82   \n",
       "1943             0.75    0.83        0.74  0.85          0.84  0.93     0.81   \n",
       "996              0.62    0.87        0.34  0.74          0.70  0.94     0.56   \n",
       "\n",
       "      f1_real  \n",
       "249      0.87  \n",
       "730      0.73  \n",
       "1599     0.88  \n",
       "1583     0.88  \n",
       "1943     0.87  \n",
       "996      0.82  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/30880511/pandas-groupby-category-rating-get-top-value-from-each-category\n",
    "results.loc[results.groupby('weight scheme')[\"cv-roc\"].agg('idxmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
